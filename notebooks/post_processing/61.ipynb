{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Section 6.1: Hyperparameter optimization\n",
    "In this notebook, we outline the post-processing procedure for the hyperparameter optimization procedure. We first find the optimal parameters and then reproduce the results presented in Table 2.\n",
    "\n",
    "### Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file_optimization = \"../../data/optimization.csv\"\n",
    "source_output = '../../data/output'\n",
    "output_folder = \"../../data/paper\"\n",
    "\n",
    "os.makedirs(os.path.join(output_folder, '61'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read optimization file\n",
    "We run the optimization file containing the runtimes for each matrix and post-process the 'name' column which gives us all information on the parameter used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv(source_file_optimization, sep=\"\\t\", header=None)\n",
    "csv.columns = [\"name\", \"time\", \"std\", \"runs\", \"success\", \"real_success\"]\n",
    "csv[\"qbs\"] = csv[\"name\"].apply(lambda x: int(x.split(\"/\")[3]))\n",
    "csv[\"parameter\"] = csv[\"name\"].apply(lambda x: x.split(\"/\")[4])\n",
    "csv[\"value\"] = csv[\"name\"].apply(lambda x: x.split(\"/\")[5] if not x.split(\"/\")[5].endswith(\"txt\") else 0)\n",
    "\n",
    "csv[\"value\"] = csv[\"value\"].astype(float)\n",
    "csv[\"matrix\"] = csv[\"name\"].apply(lambda x: x.split(\"/\")[6] if len(x.split(\"/\")) == 8 else x.split(\"/\")[5])\n",
    "csv[\"type\"] = csv[\"matrix\"].apply(lambda x: x.split(\"_\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the average time if the real success is not 100, since the time then does not include the time past the last successful run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_add = csv[\"real_success\"] < 100\n",
    "numbers = np.maximum(np.array(csv[\"real_success\"]), 1)\n",
    "csv[\"time\"] = csv[\"time\"] + should_add * ((600 - csv[\"time\"] * csv[\"real_success\"]) / numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best result in absolute time\n",
    "We get the best values for the parameters in absolute time. We will use this later as the baseline parameter for the optimization in relative time (which is the actual value that we care about, giving each matrix the same weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_values = csv.groupby([\"parameter\", \"value\"]).mean(numeric_only=True)[\"time\"].reset_index()\n",
    "best_times = best_values.groupby(\"parameter\").min()[\"time\"].reset_index()\n",
    "best_values = best_values.merge(best_times, on=[\"parameter\", \"time\"], how=\"inner\")\n",
    "\n",
    "best_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we run the optimization process for relative time, usually giving the same result as for the absolute variant, but sometimes differing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv_parameters = None\n",
    "for parameter in best_values[\"parameter\"].unique():\n",
    "    csv_parameter = csv[csv[\"parameter\"] == parameter].copy()\n",
    "    csv_for_merging = csv_parameter[['matrix', 'qbs', 'value', \"time\"]].copy()\n",
    "    # merge the time of the best value on each matrix\n",
    "    parameter_value = best_values[best_values[\"parameter\"] == parameter][\"value\"].values[0]\n",
    "    csv_parameter = csv_parameter.merge(csv_for_merging[csv_for_merging[\"value\"] == parameter_value], on=[\"matrix\", \"qbs\"], how=\"inner\")\n",
    "    if all_csv_parameters is None:\n",
    "        all_csv_parameters = csv_parameter\n",
    "    else:\n",
    "        all_csv_parameters = pd.concat([all_csv_parameters, csv_parameter])\n",
    "\n",
    "all_csv_parameters[\"relative\"] = all_csv_parameters[\"time_x\"] / all_csv_parameters[\"time_y\"]\n",
    "\n",
    "grouped = all_csv_parameters[[\"relative\", \"parameter\", \"value_x\"]].groupby([\"parameter\", \"value_x\"]).mean()\n",
    "output = dict()\n",
    "# get value optimal for each parameter\n",
    "for parameter in grouped.index.get_level_values(0).unique():\n",
    "    # set parameter equal to the value that has the lowest relative time\n",
    "    output[parameter] = grouped.loc[parameter].idxmin().values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the names to those used in the paper and only include the parameters we actually optimized using this procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naming_conversion = {\n",
    "    'n-norm': r'n_{\\text{norm}}',\n",
    "    'pid': r'P_{\\text{Id}}',\n",
    "    'start-temp': 'T(0)',\n",
    "    'n-start-gates': r'\\ell',\n",
    "    'iterations-factor': r'n_{\\text{step}} / (n\\ell)',\n",
    "}\n",
    "\n",
    "output = {naming_conversion[k]: v for k, v in output.items() if k in naming_conversion.keys()}\n",
    "os.makedirs(os.path.join(output_folder, '61'), exist_ok=True)\n",
    "json.dump(output, open(os.path.join(output_folder, \"61\", \"parameters.json\"), \"w\"), indent=4)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results in Table 2\n",
    "We determine the average speedup provided by the normal Synthetiq versus Synthetiq with some parameter changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_only_table2 = csv[csv[\"parameter\"].isin([\"\", \"no-resynth\", \"simple\", \"no-perms\"])] \n",
    "csv_normal = csv_only_table2[csv_only_table2[\"parameter\"] == \"\"]\n",
    "csv_normal = csv_normal[[\"matrix\", \"qbs\", \"time\"]]\n",
    "csv_only_merged = csv_only_table2.merge(csv_normal, on=[\"matrix\", \"qbs\"], how=\"inner\")\n",
    "csv_only_merged[\"relative\"] = csv_only_merged[\"time_x\"] / csv_only_merged[\"time_y\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_only_merged = csv_only_merged[csv_only_merged[\"parameter\"] != \"\"]\n",
    "grouped = csv_only_merged[[\"relative\", \"parameter\", \"type\"]].groupby([\"parameter\", \"type\"]).mean()\n",
    "grouped.to_csv(os.path.join(output_folder, '61', \"table2.csv\"))\n",
    "grouped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
